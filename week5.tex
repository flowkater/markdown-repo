


\subsection{고유값, 고유벡터의 기하학적 의미}


\begin{theorem}

고유값 고유벡터는 부분공간의 벡터의 집합에 속하는 벡터 $\vec{x}_i$ 가 고유값 $\lambda$ 와 고유벡터 $\vec{v}$와 오차 즉, $\Vert \lambda\vec{v} - \vec{x} \Vert$ 가 최소가 되는 벡터 장축 $\lambda\vec{x}$를 의미한다. 즉, 가장 오차가 적은 벡터 장축으로 근사한다.

\end{theorem}

\newpage
문제1. $A=\begin{bmatrix}4 & 5 \\ 2 & -3\end{bmatrix}$ 이고 $A\vec{x} = \lambda\vec{x}$ 일때, $\lambda$ 와 $\vec{x}$ (벡터공간 $E_{\lambda}$) 를 구하시오.

문제2. 고유값, 고유벡터의 기하학적 의미에 대해 적어보시오.
\newpage
\subsection{상(하)삼각(또는 대각)행렬에서의 고유값}

\begin{theorem}
상삼각행렬(또는 하삼각, 대각)행렬인 A_{n \times n}이 있을때, A의 대각 성분들은 모두 고유값이다.

$det(A) = \prod_{i=1}^{n} {pivot_i} = \prod_{i=1}^{n} {d_i} = \prod_{i=1}^{n} {\lambda_i}$
\end{theorem}

\begin{theorem}
상삼각행렬(또는 하삼각, 대각)행렬인 A_{n \times n}이 있을때, A의 대각 성분합은 A의 고유값의 합과 같다.

$tr(A) = \sum_{i=1}^{n} a_{ii} = (a_{11} + a_{22} + \cdots + a_{nn}) = \sum_{i=1}^n\lambda_{i}$
\end{theorem}


\newpage
문제1. $A=\begin{bmatrix} 1&4&5 \\ 0&{3\over 4}&6 \\ 0&0&-{1 \over 2} \end{bmatrix}$ 이고 $A\vec{x} = \lambda\vec{x}$ 일때, $\lambda$ 와 $\vec{x}$ (벡터공간 $E_{\lambda}$) 를 구하시오.
\newpage
\subsection{닮음 행렬 (Similar matrix)}

문제1. $T: R^2 \rightarrow R^2$   $T(\vec{x}) = A\vec{x}$ 이고 $A=\begin{bmatrix} 3 & -2 \\ 2 & -2 \end{bmatrix}$ 이다. $R^2$의 기저 집합 $B = \{ \begin{bmatrix} 1 \\ 2\end{bmatrix}, \begin{bmatrix} 2 \\ 1\end{bmatrix} \}$ 일때, 

1) $[T(\vec{x})]_B = D[\vec{x}]_B$ 의 $D$를 구하시오.

2) $\vec{x}=\begin{bmatrix}1 \\ -1 \end{bmatrix}$ 일때, $\vec{x} \rightarrow [\vec{x}]_B \rightarrow [T(\vec{x})]_B \rightarrow T(\vec{x})$ 방향으로 $T(\vec{x})$ 를 구하시오.


\newpage
\begin{theorem}
선형변환 $T: R^n \rightarrow R^n$ 일때,

$B = \{ v_1, v_2 \cdots v_n  \}$ 이다. $B$는 $R^n$의 기저

$\vec{x} \in R^n$ 일때, 기저 $B$에 대한 $\vec{x} 는 [\vec{x}]_B$ 이다.

$\vec{x} = C[\vec{x}]_B$ - $C$는 표준 기저에서 $B$ 기저를 위한 기저 변환 행렬

$T(\vec{x}) = A\vec{x}$ - $A$는 표준 기저에 대한 선형 변환 행렬

$[T(\vec{x})]_B = D[\vec{x}]_B$ - $D$는 기저집합 $B$에 대한 선형 변환 행렬

$D = C^{-1}AC$

$A = CDC^{-1}$
\end{theorem}

\begin{definition} 

$A,B$ 가 정방행렬일 때, $B=P^{-1}AP$를 만족하는 가역행렬 $P$가 존재하면, $B$는 $A$와 닮았다(similar)고 한다. 이때, $A$와 $B$는 닮음행렬(similar matrix)이라 한다.

\end{definition}

\begin{theorem}

모든 닮음행렬에 대하여 공유되는 성질을 닮음불변(similarity invariant) 또는 닮음에 의한 불변(invariant under simliarity)라 한다.

$A, B$가 정방행렬이고 $B=P^{-1}AP$ 일때,

- 행렬식 - $A$와 $B$는 같은 행렬식을 가진다.
- 가역성 - $A$가 가역 $\iff$ $B$가 가역
- Rank - $Rank(A) = Rank(B)$
- Nullity - $Nullity(A) = Nullity(B)$
- 대각합(trace) - $tr(A) = tr(B)$
- 특성방정식 - $A$와 $B$는 같은 특성방정식을 가진다.
- 고유값(eigenvalues) - $A$와 $B$는 같은 고유값을 가진다.
- 고유공간의 차원 - $\lambda$ 가 $A$의 고유값이면 $P^{-1}AP$의 고유값이고, $\lambda$ 에 대응하는 $A$의 고유공간과 $\lambda$ 에 대응하는 $P^{-1}AP$의 고유공간은 같은 차원을 가진다.

1) $det(B)=det(P^{-1}AP)=det(P^{-1})det(A)det(P)= {1 \over det(P)}det(A)det(P)=det(A)$

2) $tr(B) = tr(P^{-1}AP) = tr(APP^{-1}) = tr(AI) = tr(A)$

\end{theorem}

\begin{lemma} 
닮음행렬들은 행렬식이 같기 때문에, 특성방정식, 고유값도 같다. 복잡한 행렬문제를 훨씬 단순한 모양의 닮음행렬을 찾아서 간단히 처리 가능
\end{lemma}
\newpage
문제1.$A=\begin{bmatrix}1 &0&0\\0&1&0\\0&0&-1\end{bmatrix}, P=\begin{bmatrix}1&0&0\\0&0&1\\0&1&0\end{bmatrix}$ 일때, $A$의 닮음행렬 $B=P^{-1}AP$ 를 구하고 $det(A)=det(B)$가 같은지 $tr(A)=tr(B)$가 같은지 보여라.
\newpage
\subsection{대각화 고유분해 (Diagonalization and Eigen Decomposition)}

\begin{definition} 
정방행렬 $A$가 어떠한 대각행렬과 닮았으면, 즉 $P^{-1}AP$ 가 대각행렬이 되는 가역행렬 P가 존재하면 대각화가능(diagonalizable)하다고 한다. 이 경우에 행렬 P는 A를 대각화한다(diagonalize)고 한다.
\end{definition}
\begin{theorem}
  
$A$가 $n \times n$ 이면

$A$는 대각화 가능 $\iff$ $A$는 $n$개의 선형독립인 고유벡터를 가진다.

\end{theorem}

\begin{definition} 
대각화 고유분해 (Egien Decomposition)

$A = S\Lambda S^{-1}$

$A\vec{x} = \lambda\vec{x}$ 일때

고유값 $\lambda_{i}$ 에 해당하는 고유벡터  $\vec{e_i}$ 일때,

$S=\begin{bmatrix} \vec{e_1} & \vec{e_2} & \cdots & \vec{e_n} \end{bmatrix}$  $ \Lambda = \begin{bmatrix} \lambda_1 & 0 & \cdots & 0 \\ 0 & \lambda_2& \cdots&0 \\ \vdots&\vdots& \ddots & \vdots \\ 0 &0&\cdots&\lambda_n  \end{bmatrix}$

$A\vec{e_i} = \lambda_i\vec{e_i} $

$\begin{bmatrix}A\vec{e_1} &A\vec{e_2}&\cdots&A\vec{e_n} \end{bmatrix} = \begin{bmatrix}\lambda_1\vec{e_1} &\lambda_2\vec{e_2}&\cdots&\lambda_n\vec{e_n} \end{bmatrix}$

$A\begin{bmatrix}\vec{e_1} &\vec{e_2}&\cdots&\vec{e_n} \end{bmatrix} = \begin{bmatrix}\vec{e_1} &\vec{e_2}&\cdots&\vec{e_n} \end{bmatrix}\begin{bmatrix} \lambda_1 & 0 & \cdots & 0 \\ 0 & \lambda_2& \cdots&0 \\ \vdots&\vdots& \ddots & \vdots \\ 0 &0&\cdots&\lambda_n  \end{bmatrix}$

$AS=S\Lambda$

S가 가역(invertible)이라면,

$A = S\Lambda S^{-1}$
\end{definition}

\newpage
문제1. $A=\begin{bmatrix}{1 \over 2} & {1 \over 2} \\ {1 \over 2} & {1 \over 2}\end{bmatrix}$ 행렬 $A$를 $A = S\Lambda S^{-1}$ 형태로 대각화하여라.



문제2. $A=\begin{bmatrix}0 & -1 \\ 1 & 0\end{bmatrix}$ 행렬 $A$를 $A = S\Lambda S^{-1}$ 형태로 대각화하여라.


\newpage
\subsection{고유값이 모두 다르다면 고유벡터는 모두 선형독립이다. (If Eigenvalues are different, then Eigenvectors are Linearly Independent)}

\begin{theorem}

$A\vec{x}=\lambda\vec{x}$ 일때, $\lambda_1,  \lambda_2, \cdots  \lambda_n$ 고유값이 **모두 다르다면** 각각에 해당하는 $\vec{e_1}, \vec{e_2}, \cdots \vec{e_n}$은 모두 선형독립이다.

\end{theorem}
\newpage
문제1. $A\vec{x}=\lambda\vec{x}$ 일때, $\lambda_1,  \lambda_2, \cdots  \lambda_n$ 고유값이 **모두 다르다면** 각각에 해당하는 $\vec{e_1}, \vec{e_2}, \cdots \vec{e_n}$은 모두 선형독립이다. 를 증명하시오. 
\newpage
\subsection{고유벡터의 형태가 달라도 대각화의 결과는 같다. (Eigenvector is not unique, since k(e))}

\begin{theorem}

$A = S\Lambda S^{-1}$ 일때, 고유벡터를 열벡터로 하는 행렬 S는 unique 하지 않다. $k\vec{e}$ 형태이기 때문이다. 즉,$A = S\Lambda S^{-1}$ 의 형태는 다양할 수 있다.

\end{theorem}


\newpage
\subsection{고유값의 순서와 고유벡터의 순서는 일치해야 한다. (The order of eigenvalues is same with that of eigenvectors)}

\begin{theorem}

$A = S\Lambda S^{-1}$ 일때, 고유값의 순서와 고유벡터의 순서는 일치해야 한다.

\end{theorem}


\newpage
\subsection{nxn 행렬이 항상 서로 다른 n 개의 고유값을 가지는 것은 아니다. (Not all matrices have n linearly independent Eigenvectors)}

\begin{theorem}

$A_{n \times n}$인 모든 행렬에 대해서 모든 고유벡터가 선형독립이 아닐수 있기 때문에  $A = S\Lambda S^{-1}$ 가 항상 성립하는 것은 아니다. (고유값이 중복되면 같은 고유벡터를 가진다.)

\end{theorem}


\newpage
\subsection{고유값, 고유벡터의 거듭제곱 (Eigenvalue power = matrix A power)}

\begin{theorem}

\lambda 가 정방행렬 A의 고유값이고 벡터 \vec{e}가 그에 대응하는 고유벡터일때, k가 양수이면 \lambda^k 는 A^k 의 고유값이고 \vec{e}는 그에 대응하는 고유벡터이다.

$A^k\vec{e} = \lambda^k\vec{e}$

$A^k = S\Lambda^k S^{-1}$    ($\Lambda^k=\begin{bmatrix} \lambda_1^k & 0 & \cdots & 0 \\ 0 & \lambda_2^k& \cdots&0 \\ \vdots&\vdots& \ddots & \vdots \\ 0 &0&\cdots&\lambda_n^k  \end{bmatrix}$)
\end{theorem}

\newpage\newpage
\subsection{정사영 복습 (Projection Review)}

\newpage\newpage
\subsection{복소수 (Complex Number)}

\begin{definition} 
$z=a+jb \quad (j^2 = -1)$ 일때 z를 복소수(Complex number)라고 한다. 이때, a를 실수(real part) b를 허수(imaginary part)라고 한다.
\end{definition}
\newpage
\subsection{복소수 특징 및 극형식}

\begin{definition} 
$z=a+jb \quad (j^2 = -1)$ 일때,

$\vert z \vert =$ 복소수 z의 크기 $= \sqrt{a^2 + b^2}$

$\theta = arg\{z\} = z$ 복소수의 편각 = $tan^{-1}{b \over a}$

$a = rcos\theta, b = rsin\theta$ (오일러 공식에 의해)

$z=a+jb=r(cos\theta + jsin\theta) = re^{j\theta}$ (극형식-polar form)
\end{definition}
\newpage
\subsection{켤레복소수와 복소수 길이 (Complex Conjugate and Magnitude of Complex number)}

\begin{definition} 
켤레복소수(Complex Conjugate)

$z^{\ast} = a - jb = re^{-j\theta}$ 원래 복소수에서 실수축에 대칭인 복소수

$\vert z \vert^2 = zz^{\ast} = re^{j\theta}re^{-j\theta} = r^2e^{j\theta-j\theta} = r^2$
\end{definition}
\newpage
\subsection{복소 벡터와 에르미트 (Complex Vector and Hermite)}

\begin{definition} 
복소 벡터 (Complex Vector)

$\vec{x} = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix} \quad x_k = a_k + jb_k$

\end{definition}

\begin{definition} 
복소 벡터의 길이

$\vec{x} \cdot \vec{x} = \Vert \vec{x} \Vert^2 = \vert x_1 \vert^2 + \vert x_2 \vert^2 + \cdots + \vert x_n \vert^2 = x_1^{\ast}x_1 + x_2^{\ast}x_2 + \cdots + x_n^{\ast}x_n = (\vec{x}^{T})^{\ast}\vec{x}$

\end{definition}

\begin{definition} 
에르미트 벡터

복소벡터에 켤레 전치를 한 것을 에르미트(Hermite) 벡터라고 하며 H로 표현한다.

$(\vec{x}^{T})^{\ast} = \vec{x}^H$
\end{definition}

\newpage
\subsection{복소 벡터의 내적 (Inner Product of Complex Vector)}

\begin{definition} 
실수벡터 내적

$\vec{x} \cdot \vec{y} = \vec{y} \cdot \vec{x} \iff \vec{x}^T\vec{y} = \vec{y}^T\vec{x}$

\end{definition}

\begin{definition} 
복소벡터의 내적

$(\vec{x}^T)^{\ast}\vec{y} = \vec{x}^H\vec{y}$

$\vec{x}^{H}\vec{y} \ne \vec{y}^{H}\vec{x}$

\end{definition}

\newpage
문제1. $(1 + j)^{\ast}(1 + 2j)$ 와 $(1+2j)^{\ast}(1+j)$ 가 같은지 다른지 보여라.


\newpage
\begin{theorem}
복소벡터의 직교

1) $\vec{x} \cdot \vec{y} = \vec{x}^H\vec{y} = 0 = \vec{y}^H\vec{x}$

if) $\vec{x}^H\vec{y} = \vec{y}^H\vec{x} \rightarrow$ 실수 $(\vec{x}^H\vec{y})^H \quad (z_1z_2)^{\ast} = z_1^{\ast}z_2^{\ast}$

2) $\Vert \vec{x}\Vert^2 = \vec{x}^H\vec{x}$

3) $(AB)^H = B^HA^H$
\end{theorem}


\newpage
문제2. $A = \begin{bmatrix}2+j & 3j \\ 4+j & 5 \\ -1 & 0  \end{bmatrix}$ 일때 $A^H$ 를 구하여라
\newpage
\subsection{에르미트 행렬 (Hermitian Matrix)}

\begin{definition} 
대칭행렬(Symmetric matrix)

실수 행렬 $A$가 $A^T=A$ 일때 대칭행렬(Symmetric matrix) 이라 한다.

\end{definition}

\begin{definition} 
에르미트 행렬(Hermitian matrix)

복소수 행렬 $A$가 $A^H=A$ 일때 에르미트 행렬(Hermitian matrix) 이라 한다.

\end{definition}

\begin{theorem}
에르미트 행렬 $A$의 각 원소를 $a_{ij}$ 라 할때,

$\begin{cases} a_{ij} = a_{ji}^{\ast} (i \ne j) \\ a_{ii} = real (i=j)  \end{cases}$
\end{theorem}



\begin{theorem}
복소수는 실수를 포함한다. 즉,

에르미트 행렬의 성질은 대칭 행렬이 그대로 가진다.
\end{theorem}


\newpage
\subsection{에르미트 행렬의 2차 형식은 실수이다. (Quadratic form of Hermitian Matrix is real)}

\begin{definition} 
$A^H=A$ (복소수 행렬) 또는 $A^T=A$ (실수 행렬)

$\vec{x}^HA\vec{x}$ 를 2차 형식(quadratic form)이라고 한다. 

$\begin{bmatrix}x & y \end{bmatrix}\begin{bmatrix}a & 0 \\ 0 & b \end{bmatrix}\begin{bmatrix}x \\ y \end{bmatrix} = ax^2 + by^2$

\end{definition}


\begin{theorem}
$A^H=A$  일때,  $\vec{x}^HA\vec{x}$ 는 항상 실수이다.

$(\vec{x}A\vec{x})^H=\vec{x}A^H\vec{x}=\vec{x}^HA\vec{x} \rightarrow$ 실수

($z=z^{\ast}$ 이면 실수이다.)
\end{theorem}



\begin{theorem}
$R=A^HA$ 일때, $\vec{x}R\vec{x}$ 는 항상 양수이다.

$\vec{x}^HR\vec{x} = \vec{x}^HA^HA\vec{x} = (A\vec{x})^H(A\vec{x}) = \Vert A\vec{x} \Vert^2 \ge 0$

($A^HA$ 형태의 행렬의 이차 형식을 구하면 항상 양수)
\end{theorem}



\begin{theorem}

$R=A^HA$ 인 R 행렬은 항상 에르미트(또는 대칭) 행렬이다. ($R^H=R$ (복소수), $R^T=R$(실수))

\end{theorem}

$(A^H)^H = A$ 이고 $(AB)^H = B^HA^H$ 이다.

$(A^HA)^H=A^H(A^H)^H=A^HA$ 이다. 

즉, $R^H=R$


\newpage
\subsection{에르미트 행렬의 모든 고유값은 실수이다. (Every Eigenvalues of Hermitian Matrix are real)}

\begin{theorem}
$A^H=A$ 에르미트 행렬 A가 있을때,

A의 모든 고유값(eigenvectors)은 실수이다.
\end{theorem}

증명) $A\vec{x} = \lambda\vec{x}$

$\vec{x}^HA\vec{x} = \lambda\vec{x}^{\ast}\vec{x} = \lambda\Vert\vec{x}\Vert^2$

$\lambda = {\vec{x}^HA\vec{x} \over \Vert\vec{x}\Vert^2}$

만약 $R=A^HA$ 이면

$R\vec{x} = \lambda\vec{x} $

$\lambda ={\vec{x}^HR\vec{x} \over \Vert\vec{x}\Vert^2} \ge 0$




\newpage
\subsection{에르미트 행렬의 모든 고유값은 직교이다. (Every Eigenvectors of Hermitian Matrix are orthogonal)}

\begin{theorem}
$A^H=A$ 에르미트 행렬 $A$가 있을때,

$A$의 모든 고유벡터(eigenvectors)는 직교(orthogonal)이다.
\end{theorem}

증명) $A\vec{x_1}=\lambda_1\vec{x_1},\  A\vec{x_2}=\lambda_2\vec{x_2} \quad (\lambda_1 \ne \lambda_2)$

$A\vec{x_1}\cdot\vec{x_2}=(A\vec{x_1})^H\vec{x_2}=\vec{x_1}^HA^H\vec{x_2}=\vec{x_1}^HA\vec{x_2}=\vec{x_1}^H\lambda_2\vec{x_2}=\lambda_2\vec{x_1}^H\vec{x_2}$

$(A\vec{x_1})^H\vec{x_2}=(\lambda_1\vec{x_1})^H\vec{x_2}=\lambda_1^{\ast}\vec{x_1}^H\vec{x_2}=\lambda_1\vec{x_1}^H\vec{x_2}$

$\lambda_2\vec{x_1}^H\vec{x_2} = \lambda_1\vec{x_1}^H\vec{x_2}$

$(\lambda_2- \lambda_1)\vec{x_1}^H\vec{x_2}=0 \quad (\lambda_2 \ne \lambda_1)$

$\vec{x_1}^H\vec{x_2}=0$

$\vec{x_1} \cdot \vec{x_2} = 0$

$\therefore \vec{x_1}$ 과 $\vec{x_2}$는 직교한다.


\newpage
문제1. $A=\begin{bmatrix}1 & -1 \\ -1 & 2\end{bmatrix}$ 이고 $A\vec{x}=\lambda\vec{x}$ 일때, $A$의 고유벡터들이 직교하는가?
\newpage
\subsection{스펙트럴 정리 (Spectral Theorem)}

\begin{definition} 
정규직교행렬

$Q$는 서로 정규직교(Orthonormal)하는 열벡터 $q_i$ 로 이루어진 행렬이다.

$Q=\begin{bmatrix} q_1 & q_2 & \cdots & q_n \end{bmatrix}$  $q_i^Tq_j = \begin{cases} 0 \ (i \ne j) \\ 1 \ (i =j) \end{cases}$

$Q^TQ=I$ 이기 때문에

$Q^{-1}=Q^T$

\end{definition}

\begin{theorem}
스펙트럴 정리 (Spectral Theorem)

$A$가 $n \times n$ 대칭행렬 (Symmetric Matrix) 일때, $A$가 각 고유값 $\lambda_1,\lambda_2, \cdots, \lambda_n$ 이 있고 그에 대응하는 고유벡터$ \vec{x_1}, \vec{x_2}, \cdots, \vec{x_n} $이 있다.

이때, $\Vert \vec{x_i} \Vert^2 = 1$ 이라고 하면 (각 고유벡터의 길이가 1)

$A=S\Lambda S^{-1} = Q\Lambda Q^{-1} = Q\Lambda Q^{T}$

$Q\Lambda Q^{T} = \begin{bmatrix} \vec{x_1} & \vec{x_2} & \cdots & \vec{x_n} \end{bmatrix} \begin{bmatrix} \lambda_1 & 0 & \cdots & 0 \\ 0 & \lambda_2& \cdots&0 \\ \vdots&\vdots& \ddots & \vdots \\ 0 &0&\cdots&\lambda_n  \end{bmatrix} \begin{bmatrix} -\vec{x_1}^T- \\ -\vec{x_2}^T- \\ \vdots \\ -\vec{x_n}^T- \end{bmatrix}$

$A=\lambda_1\vec{x_1}\vec{x_1}^T+\lambda_2\vec{x_2}\vec{x_2}^T+ \cdots + \lambda_n\vec{x_n}\vec{x_n}^T$
\end{theorem}



(행렬곱 $AB=\begin{bmatrix}\vec{a_1} & \vec{a_2} \end{bmatrix}\begin{bmatrix}-\vec{b_1}^T- \\ -\vec{b_2}^T- \end{bmatrix}$)



\newpage
\subsection{유니타리 행렬 (Unitary Matrix)}

\begin{definition} 
복소수 행렬 $U$가 있을때,

$U^HU = UU^H = I \quad (U^H=U^{-1})$ 인 행렬 $U$를 유니타리 행렬 (Unitary Matrix)이라 한다.

정규직교행렬 $Q (Q^TQ=I)$은 실수 유니타리 행렬 $U (U^TU=I)$은 복소수이다.

\end{definition}

\newpage
\subsection{유니타리 행렬은 각도와 길이가 유지되는 선형변환이다.}

\begin{theorem}
$U^HU=I$ 인 유니타리 행렬 U는 각도와 길이가 유지되는 선형변환이다.

$(Q\vec{x})^T(Q\vec{y})=\vec{x}^TQ^TQ\vec{y}=\vec{x}^T\vec{y}$

$\Vert Q\vec{x} \Vert^2=(Q\vec{x})^TQ\vec{x}=\vec{x}^TQ^TQ\vec{x}=\vec{x}^T\vec{x}=\Vert \vec{x} \Vert^2$

$(U\vec{x})^H(U\vec{y})=\vec{x}^H\vec{y}$

$\Vert U\vec{x} \Vert^2 = \Vert \vec{x} \Vert^2$
\end{theorem}


\newpage
\subsection{유니타리 행렬의 각 고유값의 크기는 1이다. }

\begin{theorem}
$U^HU=I$ 인 유니타리 행렬 U의 각 고유값의 크기는 1이다.

$\vert \lambda_i \vert = 1$

$\Vert U\vec{x} \Vert = \Vert \lambda\vec{x} \Vert = \vert \lambda \vert \Vert \vec{x} \Vert $

$\Vert \vec{x} \Vert =\vert \lambda \vert \Vert \vec{x} \Vert $

$\vert \lambda \vert=1$


$\lambda_i^{\ast}\lambda_i=1$

$\lambda_j^{\ast}\lambda_j=1$

$\lambda_i^{\ast}\lambda_j \ne 1  \ (i \ne j)$

\end{theorem}
\newpage
\subsection{유니타리 행렬의 모든 고유벡터는 정규직교이다.}

\begin{theorem}
$U^HU=I$ 인 유니타리 행렬 U의 고유벡터들은 정규직교(orthonormal)이다.
\end{theorem}

증명)

$U\vec{x_1} = \lambda_1\vec{x_1},\quad U\vec{x_2} = \lambda_2\vec{x_2} \quad (\lambda_1 \ne \lambda_2)$

$\vec{x_1} \cdot \vec{x_2} = 0$ 이면 직교이다.

$\vec{x_1}^H\vec{x_2}= (U\vec{x_1})^H(U\vec{x_2})=(\lambda_1\vec{x_1})^H(\lambda_2\vec{x_2})=\lambda_1^{\ast}\vec{x_1}^H(\lambda_2\vec{x_2})=\lambda_1^{\ast}\lambda_2\vec{x_1}^H\vec{x_2}$

$\vec{x_1}^H\vec{x_2}=\lambda_1^{\ast}\lambda_2\vec{x_1}^H\vec{x_2}$

$\vec{x_1}^H\vec{x_2}-\lambda_1^{\ast}\lambda_2\vec{x_1}^H\vec{x_2}=0$

$(1-\lambda_1^{\ast}\lambda_2)\vec{x_1}^H\vec{x_2}=0$

$\begin{cases} \lambda_1 \ne \lambda_2 \\ \lambda_1^{\ast}\lambda_1=1 \\ \lambda_1^{\ast}\lambda_2\ne 1 \end{cases} \quad (1-\lambda_1^{\ast}\lambda_2) \ne 0$

$\vec{x_1}^H\vec{x_2}=0$

$\therefore \vec{x_1} \cdot \vec{x_2} = 0$

즉, 고유벡터는 직교한다.

(고유벡터 $\vec{e}$는 $c\vec{e}$ 이기 때문에 길이가 1인 고유벡터 형태를 고르면 된다.)


\newpage
\subsection{A'A와 A의 행렬공간}

\begin{theorem}
$m \times n$ 행렬 $A$가 있다고 할때,

$\vec{x} \in N(A)$ 이면 $\vec{x} \in N(A^TA)$

$\vec{x} \in N(A^T)$ 이면 $\vec{x} \in N(AA^T)$
\end{theorem}

증명)

$𝐴\vec{𝐱} = 0$

$𝐴^T𝐴\vec{𝐱} = 0$

$\vec{x} \in N(A^TA)$

$N(A) \subseteq N(A^TA)$



$𝐴^T𝐴\vec{𝐱} = 0$

$x^T𝐴^T𝐴\vec{𝐱} = 0$

$(A\vec{x})^T(A\vec{x}) = 0$

$\Vert A\vec{x} \Vert^2 = 0$

$A\vec{x} = 0$

$x \in N(A)$

$N(A^TA) \subseteq N(A)$



\begin{theorem}
$m \times n$ 행렬 $A$가 있을때,

$rank(A^TA) = rank(AA^T) = rank(A) = rank(A^T)$
\end{theorem}

증명.

$Rank(A^TA) = Rank(AA^T)$

$N(A^TA) = N(A)$

$Nullity(A^TA) = Nullity(A)$

$A^TA_{n \times n}, A_{m \times n}$

$Rank(A^TA) + Nullity(A^TA) = n$

$Rank(A) + Nullity(A) = n$

$Rank(A^TA) = Rank(A)$

$Rank(A) = Rank(A^T)$





\begin{theorem}
$m \times n$ 행렬 $A$가 있다고 할때,

$C(A^T)$를 행공간 $R(A)$ 라고 하면,

$AA^T$ 또는 $AA^T$ 는 대칭(symmetric) 행렬이다.

$R(A^TA) = C(A^TA)$

$R(AA^T) = C(AA^T) $

$R(A^TA) = C(A^TA) = R(A) = C(A^T)$  (행공간)

$R(AA^T) = C(AA^T) = C(A) $  (열공간)
\end{theorem}



증명)

$R(A^TA) = N(A^TA)^{\perp} = N(A)^{\perp} = C(A^T)$

$R(AA^T) = N(AA^T)^{\perp} = N(A^T)^{\perp} = C(A)$


\newpage
\subsection{A'A 와 AA' 의 고유값은 같다.}

\begin{theorem}
$m \times n$ 행렬 $A$가 있을때,

$A^TA$ 의 고유값과 $AA^T$의 고유값은 같다.
\end{theorem}

증명)

$A^TA\vec{x} = \lambda\vec{x} \ \cdots \ (1)$

양변에 A를 곱하면

$AA^TA\vec{x} = \lambda A\vec{x}$

$AA^T(A\vec{x}) = \lambda(A\vec{x})$

$A\vec{x} = \vec{v}$

$AA^T\vec{v} = \lambda\vec{v} \ \cdots \ (2)$

(1), (2) 의 고유값 \lambda 는 일치한다.




\newpage
\subsection{특이값 분해의 정의 (Singular Value Decomposition)}

\begin{definition} 
대각화 고유분해 (Egien Decomposition)

$A = S\Lambda S^{-1}$

이때 $A$는 $n \times n$ 정방행렬이다.

\end{definition}


\begin{definition} 
특이값 분해(Singular Value Decomposition; SVD)

$A_{m \times n}=U_{m \times m}\Sigma_{m \times n}V^T_{n \times n}$

$U_{m \times m} (left \ singular \ vector)$ - 유니타리 행렬 (또는 정규직교 행렬)

$\Sigma_{m \times n} (diagonal \ matrix)$ - 대각 행렬 (고유값이 대각성 성분인 대각행렬)

$V_{n \times n} (right \ singular \ vector)$ - 유니타리 행렬 (또는 정규직교 행렬)

\end{definition}

\begin{theorem}
$A_{m \times n}$ 행렬일때,

$C(A) \in R^m \perp N(A^T) \in R^m$

$C(A^T) \in R^n \perp N(A) \in R^n$
\end{theorem}


\newpage
문제1. $A=\begin{bmatrix}1 & 1 \\ 1 & 1 \\ 0 & 0 \end{bmatrix}$ SVD를 구하라.